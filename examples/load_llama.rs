//! Example: Loading a LLaMA model from SafeTensors
//!
//! This example shows how to load a LLaMA model from a directory containing
//! config.json and .safetensors files using the mlmf library.

use candlelight::{DType, Device};
use mlmf::{LoadOptions, loader::load_safetensors};

fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Configure loading options
    let device = Device::cuda_if_available(0).unwrap_or(Device::Cpu);
    let dtype = match device {
        Device::Cuda(_) => DType::F16, // Use F16 on CUDA for memory efficiency
        _ => DType::F32,               // Use F32 on CPU for compatibility
    };

    println!("ğŸš€ Loading LLaMA model...");
    println!("ğŸ“± Device: {:?}", device);
    println!("ğŸ”¢ Data type: {:?}", dtype);

    let options = LoadOptions::new(device, dtype)
        .with_progress() // Enable progress reporting
        .without_mmap(); // Disable mmap for this example (safer for demo)

    // Load the model - replace with your model path
    let model_path = std::env::args()
        .nth(1)
        .unwrap_or_else(|| "./models/llama-7b".to_string());

    let loaded = load_safetensors(&model_path, options)?;

    // Print model information
    println!("\nâœ… Model loaded successfully!");
    println!(
        "ğŸ—ï¸  Architecture: {}",
        loaded
            .name_mapper
            .architecture()
            .map(|arch| arch.name())
            .unwrap_or("Unknown")
    );
    println!("ğŸ“Š Configuration: {}", loaded.config.summary());
    println!("ğŸ§® Total tensors: {}", loaded.raw_tensors.len());
    println!("ğŸ—ºï¸  Mapped tensors: {}", loaded.name_mapper.len());

    // Show some example tensor mappings
    println!("\nğŸ“ Example tensor name mappings:");
    let mut count = 0;
    for (hf_name, mapped_name) in loaded.name_mapper.iter() {
        if count >= 5 {
            println!("   ... and {} more", loaded.name_mapper.len() - count);
            break;
        }
        println!("   {} â†’ {}", hf_name, mapped_name);
        count += 1;
    }

    // Access specific tensors
    println!("\nğŸ” Tensor inspection:");
    if let Some(tensor) = loaded.get_tensor("wte.weight") {
        println!(
            "   Token embeddings: {:?} {:?}",
            tensor.dims(),
            tensor.dtype()
        );
    }

    if let Some(tensor) = loaded.get_tensor("h.0.attn.q_proj.weight") {
        println!(
            "   Query projection (layer 0): {:?} {:?}",
            tensor.dims(),
            tensor.dtype()
        );
    }

    // Memory usage information
    let memory_estimate =
        mlmf::validation::estimate_memory_usage(&loaded.config, dtype, Some(1), None);
    println!("\nğŸ’¾ {}", memory_estimate.summary());

    Ok(())
}
