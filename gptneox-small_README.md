# GPTNeoX-Small

A GPT-NeoX model with 123.7M parameters

## Model Details

- **Architecture:** GPT-NeoX
- **Variant:** Small
- **Parameters:** 123.7M

## Technical Specifications

| Specification | Value |
|---------------|-------|
| Architecture | GPT-NeoX |
| Parameters | 123.7M |
| Vocabulary Size | 50432 |
| Hidden Size | 768 |
| Layers | 12 |
| Attention Heads | 12 |
| Max Sequence Length | 2048 |
| Model Format | Unknown |

### Memory Requirements

- **Parameters:** 0.3 GB
- **Inference:** 1.7 GB
- **Training:** 1.2 GB
- **Recommended RAM:** 3.4 GB

## Intended Use

### Primary Use Cases
- Text generation
- Conversational AI
- Code completion
- Question answering
- Summarization

### Limitations
- May generate biased or harmful content
- Performance may vary on out-of-distribution data
- Computational requirements may limit deployment
- May generate factually incorrect information
- Limited by training data cutoff
- May struggle with complex reasoning tasks

### Out-of-Scope Uses
- Generating harmful or illegal content
- Impersonation or deception
- Critical safety applications without human oversight
- Medical diagnosis or treatment recommendations
- Legal advice or financial recommendations

### Bias Considerations
This model may exhibit biases present in training data. Users should evaluate fairness for their specific use case.

### Ethical Considerations
Consider potential misuse and ensure responsible deployment with appropriate safeguards.

## Usage

```rust
use mlmf::universal_loader::load_model;
use mlmf::LoadOptions;
use candle_core::{Device, DType};

let device = Device::cuda_if_available(0).unwrap_or(Device::Cpu);
let options = LoadOptions {
    device,
    dtype: DType::F16,
    use_mmap: true,
    validate_cuda: false,
    progress: None,
    smart_mapping_oracle: None,
};

let model = load_model("GPTNeoX-Small", options)?;
```

---

*Generated by MLMF Model Card Generator on 2025-11-11 2:04:09.2144599 +00:00:00*
