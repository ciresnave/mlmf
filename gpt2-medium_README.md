# GPT2-Medium

A GPT-2 model with 353.5M parameters

## Model Details

- **Architecture:** GPT-2
- **Variant:** Small
- **Parameters:** 353.5M

## Technical Specifications

| Specification | Value |
|---------------|-------|
| Architecture | GPT-2 |
| Parameters | 353.5M |
| Vocabulary Size | 50257 |
| Hidden Size | 1024 |
| Layers | 24 |
| Attention Heads | 16 |
| Max Sequence Length | 1024 |
| Model Format | Unknown |

### Memory Requirements

- **Parameters:** 0.7 GB
- **Inference:** 1.8 GB
- **Training:** 2.6 GB
- **Recommended RAM:** 3.6 GB

## Intended Use

### Primary Use Cases
- Text generation
- Conversational AI
- Code completion
- Question answering
- Summarization

### Limitations
- May generate biased or harmful content
- Performance may vary on out-of-distribution data
- Computational requirements may limit deployment
- May generate factually incorrect information
- Limited by training data cutoff
- May struggle with complex reasoning tasks

### Out-of-Scope Uses
- Generating harmful or illegal content
- Impersonation or deception
- Critical safety applications without human oversight
- Medical diagnosis or treatment recommendations
- Legal advice or financial recommendations

### Bias Considerations
This model may exhibit biases present in training data. Users should evaluate fairness for their specific use case.

### Ethical Considerations
Consider potential misuse and ensure responsible deployment with appropriate safeguards.

## Usage

```rust
use mlmf::universal_loader::load_model;
use mlmf::LoadOptions;
use candle_core::{Device, DType};

let device = Device::cuda_if_available(0).unwrap_or(Device::Cpu);
let options = LoadOptions {
    device,
    dtype: DType::F16,
    use_mmap: true,
    validate_cuda: false,
    progress: None,
    smart_mapping_oracle: None,
};

let model = load_model("GPT2-Medium", options)?;
```

---

*Generated by MLMF Model Card Generator on 2025-11-11 2:04:09.2117343 +00:00:00*
